{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuciones normales\n",
    "\n",
    "La función de densidad de una variable aleatoria $X$ **normal** o **gaussiana** (univariante) con media $\\mu_X=E[X]$ y varianza $Var(X)=\\sigma_X$ viene dada por $$f_X(u)=\\frac{e^{-\\frac{(u-\\mu_X)^2}{2\\sigma_X^2}}}{\\sqrt{2\\pi\\sigma_X^2}}.$$ Que $X$ sea normal con esos parámetros se denota por $X\\sim N(\\mu_X,\\sigma^2_X)$.\n",
    "\n",
    "En la siguiente imagen, a la izquierda se muestran tres normales con la misma media pero diferente varianza (a menor varianza, la curva se vuelve mas flaca). A la derecha se muestran tres normales con la misma varianza pero diferente media (la media mueve horizontalmente a la gráfica pero no altera su forma)\n",
    "\n",
    "<img src=\"normal1.png\">\n",
    "\n",
    "Cuando $\\mu_X=0$ y $Var(X)=1$, se dice que $X$ es una normal estándar (o que está estandarizada).\n",
    "\n",
    "**Observación:** toda variable $X$ se puede estandarizar. Es decir, existe manera de obtener una variable $X^\\prime$ a partir de $X$ y cuya media es 0 y varianza es 1. A saber: $$X^\\prime=\\frac{X-E[X]}{sd(X)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal multivariante\n",
    "\n",
    "El vector aleatorio $X=(X_1,X_2,...,X_p)$ es **normal multivariante** si $a_1X_1+a_2X_2+...+a_pX_p$ es una variable aleatoria normal sin importar quiénes sean los números $a_1,a_2,\\cdots,a_p$.\n",
    "\n",
    "Esto implica, en particular, que si $X$ es un vector normal multivariante, entonces cada una de sus componentes es una variable aleatoria normal (pero **ojo**: al revés no es cierto; puedes tener que $X_1,X_2,...,X_p$ sean normales pero $X=(X_1,X_2,...,X_p)$ no sea una normal multivariante).\n",
    "\n",
    "Es **muy importante** notar que si $X$ es una normal multivariante de dimensión $p$, entonces existen un vector aleatorio $Z=(Z_1,Z_2,...,Z_m)$, con $Z_i\\sim N(0,1)$ y cuyas componentes son independientes, un vector de números $\\mu=(\\mu_1,\\mu_2,...,\\mu_p)$, y una matriz $A$ de $p\\times m$ tales que $X=AZ+\\mu$. Es decir, toda normal multivariante es una transformación afín de una normal multivariante donde cada componente es normal estándar y sus componentes son independientes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de densidad multivariante.\n",
    "\n",
    "Si $X$ es una normal multivariante de $p$ dimensiones, entonces la densidad de $X$ viene dada por $$f_X(\\vec{u})=\\frac{1}{(2\\pi)^{p/2}|\\Sigma|^{1/2}}e^{-\\frac{1}{2}\\langle \\vec{u}-\\vec{\\mu},\\Sigma^{-1}(\\vec{u}-\\vec{\\mu})\\rangle},$$ donde $\\vec{u}=(u_1,u_2,...,u_p)$ es un vector de $p$ números (es la variable independiente de la función), $\\vec{\\mu}=(\\mu_1,\\mu_2,...,\\mu_p)$ es un vector fijo de $p$ números y $\\Sigma$ es una matriz invertible simétrica y definida positiva.\n",
    "\n",
    "En este caso, resulta que $\\vec{\\mu}$ es el vector de medias de $X$ y $\\Sigma$ es la matriz de covarianzas de $X$. Esto se denota por $X\\sim N_p(\\vec{\\mu_X},\\Sigma_X)$.\n",
    "\n",
    "De lo anterior se sigue que si $X_1,X_2,...,X_p$ son normales incorrelacionadas, entonces son independientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal estándar multivariante\n",
    "\n",
    "Si el vector aleatorio $X$ es normal, se dice que es estándar si su vector de medias consiste únicamente en ceros y su matriz de covarianzas es la matriz identidad (esto es: si $X=(X_1,X_2,\\cdots,X_p)$ es tal que $E[X_i]=0$ y $\\Sigma_X$ es la matriz con $p$ filas y $p$ columnas donde todos sus elementos son 0 excepto los de la diagonal principal, cuyos valores son iguales a 1). Esto es lo mismo que decir que las $X_i$ son variables aleatorias estándar e independientes.\n",
    "\n",
    "El hecho de que $X$ sea una normal multivariante estándar lo denotamos entonces por $X\\sim N_p(\\textbf{0}_p,I_p)$\n",
    "\n",
    "¿Cómo estandarizamos una normal multivariante? Si $X\\sim N_p(\\vec{\\mu_X},\\Sigma_X)$, entonces $Z=\\Sigma_X^{-1/2}(X-\\vec{\\mu_X})$ es una normal estándar multivariante.\n",
    "\n",
    "Y de hecho el proceso inverso también es importante: si queremos obtener una $X\\sim N_p(\\vec{\\mu_X},\\Sigma_X)$, basta con tomar una $Z\\sim N_p(\\textbf{0}_p,I_p)$ y definir $X$ como $X=\\Sigma_X^{1/2}Z+\\vec{\\mu_X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones afines\n",
    "\n",
    "Otra propiedad de las normales univariantes, y que hemos ocupado implícitamente, es que si $X\\sim N(\\mu,\\sigma^2)$, entonces $aX+b\\sim N(a\\mu+b,a^2\\sigma^2)$ para cualesquiera números $a$ y $b$. Es decir, las transformaciones afines de una normal vuelven a ser normales y los nuevos parámetros son fácilmente calculables a partir de la original.\n",
    "\n",
    "Con las normales multivariantes se mantiene dicha propiedad: si $X\\sim N_p(\\vec{\\mu},\\Sigma)$, $A$ es una matriz de $q\\times p$ y $b$ es un vector, entonces $AX+b\\sim N_q(A\\vec{\\mu}+b,A\\Sigma A^T)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representaciones gráficas (caso de dos variables)\n",
    "\n",
    "En el caso de dos variables $X,Y$ tales que $(X,Y)$ es una normal bivariante, podemos observar gráficamente cómo cambian los scatterplots cuando variamos su matriz de correlaciones.\n",
    "\n",
    "<img src=\"normal2.png\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
